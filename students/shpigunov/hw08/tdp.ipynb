{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = ['shift', 'right-arc', 'left-arc', 'reduce']\n",
    "elemnt = ('parent', 'child')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "from conllu import parse\n",
    "from enum import Enum\n",
    "\n",
    "\n",
    "def get_data(path):\n",
    "    with open(path, \"r\") as f:\n",
    "        data = f.read()\n",
    "\n",
    "    trees = parse(data)\n",
    "    return trees\n",
    "\n",
    "# debug mode\n",
    "\"\"\"\n",
    "for tree in trees:\n",
    "    for node in tree:\n",
    "        head = node[\"head\"]\n",
    "        try:\n",
    "            print(\"{} <-- {}\".format(node[\"form\"],\n",
    "                                     tree[head - 1][\"form\"]\n",
    "                                     if head > 0 else \"root\"))\n",
    "        except TypeError:\n",
    "            pass\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('id', 3), ('form', 'у'), ('lemma', 'у'), ('upostag', 'ADP'), ('xpostag', 'Spsg'), ('feats', OrderedDict([('Case', 'Gen')])), ('head', 4), ('deprel', 'case'), ('deps', [('case', 4)]), ('misc', OrderedDict([('Id', '000k'), ('LTranslit', 'u'), ('Translit', 'u')]))])\n"
     ]
    }
   ],
   "source": [
    "print(trees[1][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint as pp\n",
    "\n",
    "def shift(stack, queue):\n",
    "    stack.append(queue.pop(0))\n",
    "    return stack, queue\n",
    "\n",
    "def right_arc(stack, queue, dep_arcs):\n",
    "    dep_arcs.append((stack[-1]['id'], queue[0]['id']))\n",
    "    stack, queue = shift(stack, queue)\n",
    "    return stack, queue, dep_arcs\n",
    "\n",
    "def left_arc(stack, queue, dep_arcs):\n",
    "    dep_arcs.append((queue[0]['id'], stack[-1]['id']))\n",
    "    stack.pop(-1)\n",
    "    return stack, queue, dep_arcs\n",
    "\n",
    "def reduce(stack):\n",
    "    stack.pop()\n",
    "    return stack\n",
    "\n",
    "def oracle(stack, queue, dep_arcs):\n",
    "    global ROOT\n",
    "    \n",
    "    if stack[-1] and not queue[0]:\n",
    "        return 'reduce'\n",
    "    elif stack[-1]['head'] == queue[0]['id']:\n",
    "        return 'left_arc'\n",
    "    elif queue[0]['head'] == stack[-1]['id']:\n",
    "        return 'right_arc'\n",
    "    elif stack[-1][\"id\"] in [i[0] for i in dep_arcs] and \\\n",
    "         (queue[0][\"head\"] < stack[-1][\"id\"] or \\\n",
    "         [s for s in stack if s[\"head\"] == queue[0][\"id\"]]):\n",
    "        return 'reduce'    \n",
    "    else:\n",
    "        return 'shift'\n",
    "\n",
    "def feature_extract(stack, queue, dep_arcs):\n",
    "    features = {}\n",
    "    \n",
    "    # stk_0: form, lemma, postag, feats\n",
    "    features['stk_0_form'] = stack[-1]['form']\n",
    "    features['stk_0_lemma'] = stack[-1]['lemma']\n",
    "    features['stk_0_postag'] = stack[-1]['upostag']\n",
    "    \n",
    "    if stack[-1]['feats'] != None:\n",
    "        for feat in stack[-1]['feats'].keys():\n",
    "            features['stk_0_'+feat] = stack[-1]['feats'][feat]\n",
    "    \n",
    "    # queue_0: form, lemma, postag, feats\n",
    "    features['que_0_form'] = queue[0]['form']\n",
    "    features['que_0_lemma'] = queue[0]['lemma']\n",
    "    features['que_0_postag'] = queue[0]['upostag']\n",
    "    \n",
    "    if queue[0]['feats'] != None:\n",
    "        for feat in queue[0]['feats'].keys():\n",
    "            features['que_0_'+feat] = queue[0]['feats'][feat]\n",
    "    \n",
    "    # queue_1: form, postag\n",
    "    try:\n",
    "        features['que_1_form'] = queue[1]['form']\n",
    "        features['que_1_postag'] = queue[1]['upostag']\n",
    "    except IndexError:\n",
    "        pass\n",
    "\n",
    "    # queue_2: postag\n",
    "    try:\n",
    "        features['que_2_postag'] = queue[2]['upostag']\n",
    "    except IndexError:\n",
    "        pass\n",
    "    \n",
    "    # queue_3: postag\n",
    "    try:\n",
    "        features['que_3_postag'] = queue[3]['upostag']\n",
    "    except IndexError:\n",
    "        pass\n",
    "    \n",
    "    return features\n",
    "      \n",
    "    \n",
    "    \n",
    "ROOT = OrderedDict([('id', 0), ('form', 'ROOT'), ('lemma', 'ROOT'), ('upostag', 'ROOT'),\n",
    "                    ('xpostag', None), ('feats', None), ('head', None), ('deprel', None),\n",
    "                    ('deps', None), ('misc', None)])\n",
    "\n",
    "def dep_parse(tree):\n",
    "    \"\"\"Parse dependencies for one sentence (tree)\"\"\"\n",
    "    \n",
    "    global ROOT\n",
    "    stack = [ROOT]\n",
    "    queue = tree[:]\n",
    "    dep_arcs = []\n",
    "    \n",
    "    x, y = [], []\n",
    "    \n",
    "    while len(stack) > 0 and len(queue) > 0:\n",
    "        \n",
    "        features = feature_extract(stack, queue, dep_arcs)        \n",
    "        \n",
    "        try:\n",
    "            action = oracle(stack, queue, dep_arcs)\n",
    "        except TypeError:\n",
    "            print(stack)\n",
    "            print(queue)\n",
    "            break\n",
    "        \n",
    "        x.append(features)\n",
    "        y.append(action)\n",
    "        \n",
    "        if action == 'reduce':\n",
    "            stack = reduce(stack)\n",
    "        elif action == 'left_arc':\n",
    "            stack, queue, dep_arcs = left_arc(stack, queue, dep_arcs)\n",
    "        elif action == 'right_arc':\n",
    "            stack, queue, dep_arcs = right_arc(stack, queue, dep_arcs)\n",
    "        elif action == 'shift':\n",
    "            stack, queue = shift(stack, queue)\n",
    "    \n",
    "    # return dep_arcs\n",
    "    return x, y\n",
    "\n",
    "\n",
    "def filter_trees(trees): \n",
    "    \"\"\"Delete nodes from a tree where id is not an integer\"\"\"\n",
    "    return [[token for token in tree if type(token['id']) == int] for tree in trees]\n",
    "\n",
    "\n",
    "def prepare_data(path):\n",
    "\n",
    "    X, Y = [], []\n",
    "    trees = filter_trees(get_data(path))\n",
    "    \n",
    "    for tree in trees:\n",
    "        x, y = dep_parse(tree)\n",
    "        X.extend(x)\n",
    "        Y.extend(y)\n",
    "\n",
    "    assert len(X) == len(Y)\n",
    "    \n",
    "    return X, Y\n",
    "    \n",
    "train_path = \"./corpus/uk_iu-ud-train.conllu\"\n",
    "test_path = \"./corpus/uk_iu-ud-test.conllu\"\n",
    "\n",
    "X_train, Y_train = prepare_data(train_path)\n",
    "X_test, Y_test = prepare_data(test_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Vectorizing...\n"
     ]
    }
   ],
   "source": [
    "# Vectorize features\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "def vectorize(X_train, X_test):\n",
    "    \n",
    "    print('\\nVectorizing...')\n",
    "    v = DictVectorizer(sparse=True)\n",
    "    \n",
    "    vectorizer = v.fit(X_train)\n",
    "    v_train = vectorizer.transform(X_train)\n",
    "    v_test = vectorizer.transform(X_test)\n",
    "    \n",
    "    return v_train, v_test, vectorizer\n",
    "\n",
    "X_train, X_test, vectorizer = vectorize(X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:  5.1min finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    left_arc       0.85      0.93      0.89      7346\n",
      "      reduce       0.63      0.42      0.50      2552\n",
      "   right_arc       0.79      0.82      0.80      5935\n",
      "       shift       0.86      0.86      0.86     10336\n",
      "\n",
      "   micro avg       0.83      0.83      0.83     26169\n",
      "   macro avg       0.78      0.76      0.76     26169\n",
      "weighted avg       0.82      0.83      0.82     26169\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Try a different classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=20, criterion='entropy', max_depth=None, n_jobs=-1, verbose=True)\n",
    "rfc.fit(X_train, Y_train)\n",
    "\n",
    "predicted = rfc.predict(X_test)\n",
    "print(classification_report(Y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
